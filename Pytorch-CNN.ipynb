{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "raw_data_path=os.path.join('data','raw')\n",
    "df=pd.read_csv(os.path.join(raw_data_path,'fer2013.csv'))\n",
    "X=[]\n",
    "for i in range(len(df)):\n",
    "    X.append(df.loc[i,'pixels'].split(' '))\n",
    "X=np.array(X,np.float32)/255.\n",
    "y=df.emotion.values\n",
    "X_train=X[np.where(df.Usage=='Training')]\n",
    "y_train=y[np.where((df.Usage=='Training'))]\n",
    "X_test=X[np.where((df.Usage!='Training'))]\n",
    "y_test=y[np.where((df.Usage!='Training'))]\n",
    "def balance_classes(X,y):\n",
    "    X1=X[np.where(y!=1)]\n",
    "    X2=X[np.where(y==1)]\n",
    "    X2=np.repeat(X2,9,axis=0)\n",
    "    X=np.concatenate((X1,X2),axis=0)\n",
    "    y1=y[np.where(y!=1)]\n",
    "    y2=y[np.where(y==1)]\n",
    "    y2=np.repeat(y2,9,axis=0)\n",
    "    y=np.concatenate((y1,y2),axis=0)\n",
    "    i=[i for i in range(len(y))]\n",
    "    np.random.shuffle(i)\n",
    "    return X[i],y[i]\n",
    "X_train,y_train=balance_classes(X_train,y_train)\n",
    "def one_hot_encoder(X):\n",
    "    N=len(X)\n",
    "    K=len(set(X))\n",
    "    Z=np.zeros((N,K))\n",
    "    for i in range(N):\n",
    "        c=X[i]\n",
    "        Z[i,c]=1\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = t.device(\"cuda:0\" if t.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7178"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(t.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1=t.nn.Conv2d(1,20,5,1)\n",
    "        self.conv2=t.nn.Conv2d(20,50,5,1)   \n",
    "        self.fc1=t.nn.Linear(9*9*50,500)\n",
    "        self.fc2=t.nn.Linear(500,7)\n",
    "    def forward(self,x):\n",
    "        x=t.nn.functional.leaky_relu(self.conv1(x))\n",
    "        x=t.nn.functional.max_pool2d(x,2,2)\n",
    "        x=t.nn.functional.relu(self.conv2(x))\n",
    "        x=t.nn.functional.max_pool2d(x,2,2)\n",
    "        x=x.view(-1,9*9*50)\n",
    "        x=t.nn.functional.relu(self.fc1(x))\n",
    "        x=self.fc2(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=4050, out_features=500, bias=True)\n",
       "  (fc2): Linear(in_features=500, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LeNet().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = t.nn.CrossEntropyLoss()\n",
    "optimizer = t.optim.Adam(model.parameters(), lr = 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=X_train.reshape(32197,1,48,48)\n",
    "labels=y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_inputs_X=X_test.reshape(7178,1,48,48)\n",
    "val_labels_y=y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 48, 48)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches=320\n",
    "batch_sz=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1\n",
      "training loss: 1.0202, acc 11.8117 \n",
      "validation loss: 0.0189, validation acc 17.9800 \n",
      "epoch : 2\n",
      "training loss: 1.0026, acc 12.3900 \n",
      "validation loss: 0.0185, validation acc 19.2300 \n",
      "epoch : 3\n",
      "training loss: 0.9842, acc 13.4283 \n",
      "validation loss: 0.0182, validation acc 21.6600 \n",
      "epoch : 4\n",
      "training loss: 0.9673, acc 15.1633 \n",
      "validation loss: 0.0179, validation acc 23.4300 \n",
      "epoch : 5\n",
      "training loss: 0.9505, acc 16.5933 \n",
      "validation loss: 0.0176, validation acc 24.5600 \n",
      "epoch : 6\n",
      "training loss: 0.9357, acc 17.5367 \n",
      "validation loss: 0.0174, validation acc 25.4200 \n",
      "epoch : 7\n",
      "training loss: 0.9239, acc 18.1833 \n",
      "validation loss: 0.0172, validation acc 25.9500 \n",
      "epoch : 8\n",
      "training loss: 0.9146, acc 18.6567 \n",
      "validation loss: 0.0171, validation acc 26.1800 \n",
      "epoch : 9\n",
      "training loss: 0.9074, acc 19.0450 \n",
      "validation loss: 0.0169, validation acc 26.4800 \n",
      "epoch : 10\n",
      "training loss: 0.9015, acc 19.3133 \n",
      "validation loss: 0.0169, validation acc 26.6300 \n",
      "epoch : 11\n",
      "training loss: 0.8965, acc 19.5317 \n",
      "validation loss: 0.0168, validation acc 26.9200 \n",
      "epoch : 12\n",
      "training loss: 0.8919, acc 19.7733 \n",
      "validation loss: 0.0167, validation acc 27.1700 \n",
      "epoch : 13\n",
      "training loss: 0.8876, acc 19.9833 \n",
      "validation loss: 0.0167, validation acc 27.1000 \n",
      "epoch : 14\n",
      "training loss: 0.8835, acc 20.1717 \n",
      "validation loss: 0.0166, validation acc 27.1400 \n",
      "epoch : 15\n",
      "training loss: 0.8794, acc 20.3417 \n",
      "validation loss: 0.0165, validation acc 27.2100 \n",
      "epoch : 16\n",
      "training loss: 0.8752, acc 20.5367 \n",
      "validation loss: 0.0165, validation acc 27.4400 \n",
      "epoch : 17\n",
      "training loss: 0.8713, acc 20.7550 \n",
      "validation loss: 0.0164, validation acc 27.5300 \n",
      "epoch : 18\n",
      "training loss: 0.8674, acc 20.9167 \n",
      "validation loss: 0.0164, validation acc 27.6400 \n",
      "epoch : 19\n",
      "training loss: 0.8638, acc 21.0783 \n",
      "validation loss: 0.0163, validation acc 27.8100 \n",
      "epoch : 20\n",
      "training loss: 0.8602, acc 21.2250 \n",
      "validation loss: 0.0163, validation acc 27.8500 \n",
      "epoch : 21\n",
      "training loss: 0.8567, acc 21.4000 \n",
      "validation loss: 0.0162, validation acc 27.9800 \n",
      "epoch : 22\n",
      "training loss: 0.8533, acc 21.5717 \n",
      "validation loss: 0.0162, validation acc 28.0300 \n",
      "epoch : 23\n",
      "training loss: 0.8499, acc 21.7183 \n",
      "validation loss: 0.0161, validation acc 28.2000 \n",
      "epoch : 24\n",
      "training loss: 0.8465, acc 21.9000 \n",
      "validation loss: 0.0161, validation acc 28.2100 \n",
      "epoch : 25\n",
      "training loss: 0.8431, acc 22.0450 \n",
      "validation loss: 0.0160, validation acc 28.3200 \n",
      "epoch : 26\n",
      "training loss: 0.8398, acc 22.1667 \n",
      "validation loss: 0.0160, validation acc 28.4400 \n",
      "epoch : 27\n",
      "training loss: 0.8364, acc 22.3167 \n",
      "validation loss: 0.0159, validation acc 28.4700 \n",
      "epoch : 28\n",
      "training loss: 0.8331, acc 22.4533 \n",
      "validation loss: 0.0159, validation acc 28.5900 \n",
      "epoch : 29\n",
      "training loss: 0.8297, acc 22.5867 \n",
      "validation loss: 0.0158, validation acc 28.7300 \n",
      "epoch : 30\n",
      "training loss: 0.8263, acc 22.7083 \n",
      "validation loss: 0.0158, validation acc 28.7500 \n",
      "epoch : 31\n",
      "training loss: 0.8230, acc 22.8417 \n",
      "validation loss: 0.0157, validation acc 28.8600 \n",
      "epoch : 32\n",
      "training loss: 0.8197, acc 22.9933 \n",
      "validation loss: 0.0157, validation acc 29.0900 \n",
      "epoch : 33\n",
      "training loss: 0.8163, acc 23.1250 \n",
      "validation loss: 0.0157, validation acc 29.1900 \n",
      "epoch : 34\n",
      "training loss: 0.8130, acc 23.2467 \n",
      "validation loss: 0.0156, validation acc 29.2700 \n",
      "epoch : 35\n",
      "training loss: 0.8097, acc 23.3950 \n",
      "validation loss: 0.0156, validation acc 29.3200 \n",
      "epoch : 36\n",
      "training loss: 0.8065, acc 23.5117 \n",
      "validation loss: 0.0155, validation acc 29.5400 \n",
      "epoch : 37\n",
      "training loss: 0.8032, acc 23.6383 \n",
      "validation loss: 0.0155, validation acc 29.6800 \n",
      "epoch : 38\n",
      "training loss: 0.7999, acc 23.7750 \n",
      "validation loss: 0.0155, validation acc 29.7400 \n",
      "epoch : 39\n",
      "training loss: 0.7967, acc 23.8883 \n",
      "validation loss: 0.0154, validation acc 29.8200 \n",
      "epoch : 40\n",
      "training loss: 0.7935, acc 24.0467 \n",
      "validation loss: 0.0154, validation acc 29.9900 \n",
      "epoch : 41\n",
      "training loss: 0.7903, acc 24.1583 \n",
      "validation loss: 0.0153, validation acc 30.0600 \n",
      "epoch : 42\n",
      "training loss: 0.7871, acc 24.2767 \n",
      "validation loss: 0.0153, validation acc 30.1400 \n",
      "epoch : 43\n",
      "training loss: 0.7839, acc 24.3833 \n",
      "validation loss: 0.0153, validation acc 30.1800 \n",
      "epoch : 44\n",
      "training loss: 0.7807, acc 24.5167 \n",
      "validation loss: 0.0152, validation acc 30.2200 \n",
      "epoch : 45\n",
      "training loss: 0.7775, acc 24.6333 \n",
      "validation loss: 0.0152, validation acc 30.3600 \n",
      "epoch : 46\n",
      "training loss: 0.7743, acc 24.7800 \n",
      "validation loss: 0.0152, validation acc 30.3600 \n",
      "epoch : 47\n",
      "training loss: 0.7712, acc 24.9133 \n",
      "validation loss: 0.0151, validation acc 30.5600 \n",
      "epoch : 48\n",
      "training loss: 0.7680, acc 25.0483 \n",
      "validation loss: 0.0151, validation acc 30.5900 \n",
      "epoch : 49\n",
      "training loss: 0.7649, acc 25.1800 \n",
      "validation loss: 0.0151, validation acc 30.7000 \n",
      "epoch : 50\n",
      "training loss: 0.7617, acc 25.2617 \n",
      "validation loss: 0.0150, validation acc 30.7500 \n",
      "epoch : 51\n",
      "training loss: 0.7586, acc 25.3817 \n",
      "validation loss: 0.0150, validation acc 30.8600 \n",
      "epoch : 52\n",
      "training loss: 0.7556, acc 25.4917 \n",
      "validation loss: 0.0150, validation acc 30.8700 \n",
      "epoch : 53\n",
      "training loss: 0.7525, acc 25.6283 \n",
      "validation loss: 0.0149, validation acc 30.9900 \n",
      "epoch : 54\n",
      "training loss: 0.7494, acc 25.7633 \n",
      "validation loss: 0.0149, validation acc 31.0300 \n",
      "epoch : 55\n",
      "training loss: 0.7464, acc 25.8350 \n",
      "validation loss: 0.0149, validation acc 31.1400 \n",
      "epoch : 56\n",
      "training loss: 0.7433, acc 25.9450 \n",
      "validation loss: 0.0148, validation acc 31.2800 \n",
      "epoch : 57\n",
      "training loss: 0.7403, acc 26.0383 \n",
      "validation loss: 0.0148, validation acc 31.4000 \n",
      "epoch : 58\n",
      "training loss: 0.7374, acc 26.1533 \n",
      "validation loss: 0.0148, validation acc 31.3700 \n",
      "epoch : 59\n",
      "training loss: 0.7344, acc 26.2700 \n",
      "validation loss: 0.0147, validation acc 31.4700 \n",
      "epoch : 60\n",
      "training loss: 0.7315, acc 26.3317 \n",
      "validation loss: 0.0147, validation acc 31.5700 \n",
      "epoch : 61\n",
      "training loss: 0.7286, acc 26.4617 \n",
      "validation loss: 0.0147, validation acc 31.6600 \n",
      "epoch : 62\n",
      "training loss: 0.7257, acc 26.6200 \n",
      "validation loss: 0.0146, validation acc 31.7200 \n",
      "epoch : 63\n",
      "training loss: 0.7228, acc 26.7350 \n",
      "validation loss: 0.0146, validation acc 31.8100 \n",
      "epoch : 64\n",
      "training loss: 0.7200, acc 26.8467 \n",
      "validation loss: 0.0146, validation acc 31.8900 \n",
      "epoch : 65\n",
      "training loss: 0.7172, acc 26.9333 \n",
      "validation loss: 0.0145, validation acc 32.0400 \n",
      "epoch : 66\n",
      "training loss: 0.7144, acc 27.0600 \n",
      "validation loss: 0.0145, validation acc 32.0600 \n",
      "epoch : 67\n",
      "training loss: 0.7116, acc 27.1833 \n",
      "validation loss: 0.0145, validation acc 32.1600 \n",
      "epoch : 68\n",
      "training loss: 0.7089, acc 27.2817 \n",
      "validation loss: 0.0145, validation acc 32.1600 \n",
      "epoch : 69\n",
      "training loss: 0.7062, acc 27.3583 \n",
      "validation loss: 0.0144, validation acc 32.2500 \n",
      "epoch : 70\n",
      "training loss: 0.7035, acc 27.4800 \n",
      "validation loss: 0.0144, validation acc 32.3500 \n",
      "epoch : 71\n",
      "training loss: 0.7008, acc 27.5667 \n",
      "validation loss: 0.0144, validation acc 32.3500 \n",
      "epoch : 72\n",
      "training loss: 0.6982, acc 27.6800 \n",
      "validation loss: 0.0143, validation acc 32.4500 \n",
      "epoch : 73\n",
      "training loss: 0.6956, acc 27.7783 \n",
      "validation loss: 0.0143, validation acc 32.4300 \n",
      "epoch : 74\n",
      "training loss: 0.6930, acc 27.8800 \n",
      "validation loss: 0.0143, validation acc 32.5300 \n",
      "epoch : 75\n",
      "training loss: 0.6904, acc 27.9900 \n",
      "validation loss: 0.0143, validation acc 32.6600 \n",
      "epoch : 76\n",
      "training loss: 0.6879, acc 28.0633 \n",
      "validation loss: 0.0142, validation acc 32.7600 \n",
      "epoch : 77\n",
      "training loss: 0.6854, acc 28.1233 \n",
      "validation loss: 0.0142, validation acc 32.8400 \n",
      "epoch : 78\n",
      "training loss: 0.6829, acc 28.1967 \n",
      "validation loss: 0.0142, validation acc 32.9200 \n",
      "epoch : 79\n",
      "training loss: 0.6805, acc 28.3133 \n",
      "validation loss: 0.0142, validation acc 33.0300 \n",
      "epoch : 80\n",
      "training loss: 0.6780, acc 28.3850 \n",
      "validation loss: 0.0141, validation acc 33.0600 \n",
      "epoch : 81\n",
      "training loss: 0.6756, acc 28.4550 \n",
      "validation loss: 0.0141, validation acc 33.1600 \n",
      "epoch : 82\n",
      "training loss: 0.6732, acc 28.5800 \n",
      "validation loss: 0.0141, validation acc 33.2100 \n",
      "epoch : 83\n",
      "training loss: 0.6709, acc 28.6733 \n",
      "validation loss: 0.0141, validation acc 33.3100 \n",
      "epoch : 84\n",
      "training loss: 0.6686, acc 28.7567 \n",
      "validation loss: 0.0140, validation acc 33.4200 \n",
      "epoch : 85\n",
      "training loss: 0.6663, acc 28.8300 \n",
      "validation loss: 0.0140, validation acc 33.4700 \n",
      "epoch : 86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.6640, acc 28.9183 \n",
      "validation loss: 0.0140, validation acc 33.5500 \n",
      "epoch : 87\n",
      "training loss: 0.6617, acc 29.0150 \n",
      "validation loss: 0.0140, validation acc 33.6300 \n",
      "epoch : 88\n",
      "training loss: 0.6595, acc 29.0867 \n",
      "validation loss: 0.0139, validation acc 33.7000 \n",
      "epoch : 89\n",
      "training loss: 0.6573, acc 29.1600 \n",
      "validation loss: 0.0139, validation acc 33.7000 \n",
      "epoch : 90\n",
      "training loss: 0.6551, acc 29.2267 \n",
      "validation loss: 0.0139, validation acc 33.7500 \n",
      "epoch : 91\n",
      "training loss: 0.6530, acc 29.3217 \n",
      "validation loss: 0.0139, validation acc 33.8100 \n",
      "epoch : 92\n",
      "training loss: 0.6508, acc 29.4067 \n",
      "validation loss: 0.0138, validation acc 33.9100 \n",
      "epoch : 93\n",
      "training loss: 0.6487, acc 29.5083 \n",
      "validation loss: 0.0138, validation acc 33.9800 \n",
      "epoch : 94\n",
      "training loss: 0.6466, acc 29.5800 \n",
      "validation loss: 0.0138, validation acc 34.0500 \n",
      "epoch : 95\n",
      "training loss: 0.6445, acc 29.6367 \n",
      "validation loss: 0.0138, validation acc 34.1500 \n",
      "epoch : 96\n",
      "training loss: 0.6425, acc 29.7333 \n",
      "validation loss: 0.0138, validation acc 34.2200 \n",
      "epoch : 97\n",
      "training loss: 0.6404, acc 29.8200 \n",
      "validation loss: 0.0137, validation acc 34.2600 \n",
      "epoch : 98\n",
      "training loss: 0.6384, acc 29.8967 \n",
      "validation loss: 0.0137, validation acc 34.2800 \n",
      "epoch : 99\n",
      "training loss: 0.6364, acc 29.9667 \n",
      "validation loss: 0.0137, validation acc 34.3200 \n",
      "epoch : 100\n",
      "training loss: 0.6344, acc 30.0150 \n",
      "validation loss: 0.0137, validation acc 34.4300 \n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "running_loss_history = []\n",
    "running_corrects_history = []\n",
    "val_running_loss_history = []\n",
    "val_running_corrects_history = []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "    val_running_loss = 0.0\n",
    "    val_running_corrects = 0.0\n",
    "    for j in range(n_batches):\n",
    "        Xbatch = inputs[j*batch_sz:(j*batch_sz+batch_sz)]\n",
    "        Ybatch = labels[j*batch_sz:(j*batch_sz+batch_sz)]\n",
    "        inputs_b = t.tensor(Xbatch).to(device)\n",
    "        labels_b = t.tensor(Ybatch).to(device)\n",
    "        outputs = model(inputs_b)\n",
    "        loss = criterion(outputs, labels_b)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, preds = t.max(outputs, 1)\n",
    "        running_loss += loss.item()\n",
    "        running_corrects += t.sum(preds == labels_b.data)\n",
    "    with t.no_grad():\n",
    "        val_inputs = t.tensor(val_inputs_X).to(device)\n",
    "        val_labels = t.tensor(val_labels_y).to(device)\n",
    "        val_outputs = model(val_inputs)\n",
    "        val_loss = criterion(val_outputs, val_labels)\n",
    "        _, val_preds = t.max(val_outputs, 1)\n",
    "        val_running_loss += val_loss.item()\n",
    "        val_running_corrects += t.sum(val_preds == val_labels.data)\n",
    "    epoch_loss = running_loss/len(training_loader)\n",
    "    epoch_acc = running_corrects.float()/ len(training_loader)\n",
    "    running_loss_history.append(epoch_loss)\n",
    "    running_corrects_history.append(epoch_acc)\n",
    "    val_epoch_loss = val_running_loss/len(validation_loader)\n",
    "    val_epoch_acc = val_running_corrects.float()/ len(validation_loader)\n",
    "    val_running_loss_history.append(val_epoch_loss)\n",
    "    val_running_corrects_history.append(val_epoch_acc)\n",
    "    print('epoch :', (e+1))\n",
    "    print('training loss: {:.4f}, acc {:.4f} '.format(epoch_loss, epoch_acc.item()))\n",
    "    print('validation loss: {:.4f}, validation acc {:.4f} '.format(val_epoch_loss, val_epoch_acc.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
