{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "raw_data_path=os.path.join('data','raw')\n",
    "df=pd.read_csv(os.path.join(raw_data_path,'fer2013.csv'))\n",
    "X=[]\n",
    "for i in range(len(df)):\n",
    "    X.append(df.loc[i,'pixels'].split(' '))\n",
    "X=np.array(X,np.float32)/255.\n",
    "y=df.emotion.values\n",
    "X_train=X[np.where(df.Usage=='Training')]\n",
    "y_train=y[np.where((df.Usage=='Training'))]\n",
    "X_test=X[np.where((df.Usage!='Training'))]\n",
    "y_test=y[np.where((df.Usage!='Training'))]\n",
    "def balance_classes(X,y):\n",
    "    X1=X[np.where(y!=1)]\n",
    "    X2=X[np.where(y==1)]\n",
    "    X2=np.repeat(X2,9,axis=0)\n",
    "    X=np.concatenate((X1,X2),axis=0)\n",
    "    y1=y[np.where(y!=1)]\n",
    "    y2=y[np.where(y==1)]\n",
    "    y2=np.repeat(y2,9,axis=0)\n",
    "    y=np.concatenate((y1,y2),axis=0)\n",
    "    i=[i for i in range(len(y))]\n",
    "    np.random.shuffle(i)\n",
    "    return X[i],y[i]\n",
    "X_train,y_train=balance_classes(X_train,y_train)\n",
    "\n",
    "def train_test_split(X,y,size=0.8,rs=None):\n",
    "    N=len(X)\n",
    "    np.random.seed(rs)\n",
    "    tr_i=np.random.choice(N,int(size*N),replace=False)\n",
    "    t_i=[i for i in range(N) if i not in tr_i]\n",
    "    X_train=X[tr_i]\n",
    "    y_train=y[tr_i]\n",
    "    X_test=X[t_i]\n",
    "    y_test=y[t_i]\n",
    "    return X_train,y_train,X_test,y_test\n",
    "# X_train,y_train,X_test,y_test=train_test_split(X_s,y,size=0.9,rs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.astype(np.float32)\n",
    "y_train=y_train.astype(np.float32)\n",
    "X_test=X_test.astype(np.float32)\n",
    "y_test=y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(X):\n",
    "    N=X.shape[0]\n",
    "    K=len(set(X))\n",
    "    Z=np.zeros((N,K))\n",
    "    for i in range(N):\n",
    "        c=int(X[i])\n",
    "        Z[i,c]=1\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32197, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoder(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenLayer(object):\n",
    "    def __init__(self,i,M1,M2,af='relu',rs=None):\n",
    "        self.id=i\n",
    "        self.M1=M1\n",
    "        self.M2=M2\n",
    "        self.af=af\n",
    "        \n",
    "        self.W=tf.Variable(tf.random_normal(shape=[M1,M2],stddev=np.sqrt(M1),seed=rs,dtype=tf.float32))\n",
    "        self.b=tf.Variable(tf.random_normal(shape=[M2],seed=rs,dtype=tf.float32))\n",
    "        self.params=[self.W,self.b]\n",
    "    def forward(self,X):\n",
    "        if self.af=='tanh':\n",
    "            return tf.nn.tanh(tf.matmul(X,self.W)+self.b)\n",
    "        if self.af=='sigmoid':\n",
    "            return tf.nn.sigmoid(tf.matmul(X,self.W)+self.b)\n",
    "        if self.af=='relu':\n",
    "            return tf.nn.relu(tf.matmul(X,self.W)+self.b)\n",
    "        if self.af=='leaky-relu':\n",
    "            return tf.nn.leaky_relu(tf.matmul(X,self.W)+self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(object):\n",
    "    def __init__(self,hidden_layer_size):\n",
    "        self.hidden_layer_size=hidden_layer_size\n",
    "        \n",
    "    def forward(self,X):\n",
    "        z=X\n",
    "        for h in self.hidden_layers:\n",
    "            z=h.forward(z)\n",
    "        return tf.matmul(z,self.W)+self.b\n",
    "    \n",
    "    def predict(self,X):\n",
    "        p=self.forward(X)\n",
    "        return tf.argmax(p,axis=1)\n",
    "    \n",
    "    def fit(self,X,y,lr=0.001,epochs=1000,af=None,fig=True,batch_size=2900,n_batch=10,random_state=None):\n",
    "        y=one_hot_encoder(y)\n",
    "        if af==None:\n",
    "            af=len(self.hidden_layer_size)*['relu']\n",
    "        X_t,y_t,X_v,y_v=train_test_split(X,y,size=0.9,rs=random_state)\n",
    "        c_t=[]\n",
    "        c_v=[]\n",
    "        cl_t=[]\n",
    "        cl_v=[]\n",
    "        N,D=X_t.shape\n",
    "        self.hidden_layers=[]\n",
    "        M1=D\n",
    "        cnt=0\n",
    "        for M2,a in zip(self.hidden_layer_size,af):\n",
    "            h=HiddenLayer(cnt,M1,M2,a,random_state)\n",
    "            self.hidden_layers.append(h)\n",
    "            M1=M2\n",
    "            cnt+=1\n",
    "        M2=y.shape[1]\n",
    "        self.W=tf.Variable(tf.random_normal([M1,M2],stddev=np.sqrt(M1),seed=random_state,dtype=tf.float32))\n",
    "        self.b=tf.Variable(tf.random_normal(shape=[M2],seed=random_state,dtype=tf.float32))\n",
    "        self.params=[self.W,self.b]\n",
    "        for h in self.hidden_layers:\n",
    "            self.params+=h.params\n",
    "        tfX=tf.placeholder(tf.float32,shape=[None,D])\n",
    "        tfY=tf.placeholder(tf.float32,shape=[None,M2])\n",
    "        y_p=self.forward(tfX)\n",
    "        cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_p,labels=tfY))\n",
    "        preds=self.predict(tfX)\n",
    "        optimizer=tf.train.RMSPropOptimizer(lr)\n",
    "        train=optimizer.minimize(cost)\n",
    "        with tf.Session() as s:\n",
    "            s.run(tf.global_variables_initializer())\n",
    "            for i in range(epochs):\n",
    "                for j in range(n_batch):\n",
    "                    x=X_t[j*batch_size:(j*batch_size+batch_size)]\n",
    "                    yb=y_t[j*batch_size:j*batch_size+batch_size]\n",
    "                    c_t.append(s.run(cost,feed_dict={tfX:x,tfY:yb}))\n",
    "                    c_v.append(s.run(cost,feed_dict={tfX:X_v,tfY:y_v}))\n",
    "                    cl_t.append(np.mean(s.run(preds,feed_dict={tfX:x})==np.argmax(yb,axis=1)))               \n",
    "                    cl_v.append(np.mean(s.run(preds,feed_dict={tfX:X_v})==np.argmax(y_v,axis=1)))    \n",
    "                    s.run(train,feed_dict={tfX:x,tfY:yb})\n",
    "                if i%10==0:\n",
    "                    print('Epoch {0} Train C: {1} Cl: {2} Test C: {3} Cl:{4}'.format(i,c_t[i],cl_t[i],c_v[i],cl_v[i]))\n",
    "        if fig==True:\n",
    "            plt.plot(c_t,label='Train Cost')\n",
    "            plt.plot(c_v,label='Test Cost')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            plt.plot(cl_t,label='Train Classification')\n",
    "            plt.plot(cl_v,label='Test Classification')\n",
    "            plt.legend()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=ANN((10,20,30,5,10,50,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train C: 86320177152.0 Cl: 0.14517241379310344 Test C: 86605242368.0 Cl:0.15\n",
      "Epoch 10 Train C: 84853022720.0 Cl: 0.14413793103448275 Test C: 85137424384.0 Cl:0.15\n",
      "Epoch 20 Train C: 83911434240.0 Cl: 0.14344827586206896 Test C: 84196777984.0 Cl:0.1496894409937888\n",
      "Epoch 30 Train C: 83049218048.0 Cl: 0.14344827586206896 Test C: 83335274496.0 Cl:0.14937888198757765\n",
      "Epoch 40 Train C: 82212782080.0 Cl: 0.14275862068965517 Test C: 82499878912.0 Cl:0.1484472049689441\n",
      "Epoch 50 Train C: 81389731840.0 Cl: 0.1424137931034483 Test C: 81677516800.0 Cl:0.1484472049689441\n",
      "Epoch 60 Train C: 80574717952.0 Cl: 0.1424137931034483 Test C: 80862183424.0 Cl:0.1484472049689441\n",
      "Epoch 70 Train C: 79766437888.0 Cl: 0.1424137931034483 Test C: 80053116928.0 Cl:0.14906832298136646\n",
      "Epoch 80 Train C: 78964121600.0 Cl: 0.14172413793103447 Test C: 79250759680.0 Cl:0.14875776397515528\n",
      "Epoch 90 Train C: 78168219648.0 Cl: 0.14206896551724138 Test C: 78455316480.0 Cl:0.14813664596273293\n",
      "Epoch 100 Train C: 77379166208.0 Cl: 0.14206896551724138 Test C: 77666066432.0 Cl:0.14875776397515528\n",
      "Epoch 110 Train C: 76594823168.0 Cl: 0.14172413793103447 Test C: 76881518592.0 Cl:0.14813664596273293\n",
      "Epoch 120 Train C: 75816058880.0 Cl: 0.14172413793103447 Test C: 76101689344.0 Cl:0.14782608695652175\n",
      "Epoch 130 Train C: 75043078144.0 Cl: 0.14103448275862068 Test C: 75326881792.0 Cl:0.14751552795031056\n",
      "Epoch 140 Train C: 74273906688.0 Cl: 0.1403448275862069 Test C: 74557063168.0 Cl:0.14751552795031056\n",
      "Epoch 150 Train C: 73509822464.0 Cl: 0.1413793103448276 Test C: 73792937984.0 Cl:0.14782608695652175\n",
      "Epoch 160 Train C: 72752480256.0 Cl: 0.14206896551724138 Test C: 73033949184.0 Cl:0.14782608695652175\n",
      "Epoch 170 Train C: 72000512000.0 Cl: 0.14103448275862068 Test C: 72280580096.0 Cl:0.14782608695652175\n",
      "Epoch 180 Train C: 71254745088.0 Cl: 0.14172413793103447 Test C: 71532584960.0 Cl:0.14720496894409937\n",
      "Epoch 190 Train C: 70514835456.0 Cl: 0.14103448275862068 Test C: 70789726208.0 Cl:0.14658385093167703\n",
      "Epoch 200 Train C: 69780037632.0 Cl: 0.14103448275862068 Test C: 70051364864.0 Cl:0.14751552795031056\n",
      "Epoch 210 Train C: 69050916864.0 Cl: 0.14103448275862068 Test C: 69318098944.0 Cl:0.14751552795031056\n",
      "Epoch 220 Train C: 68326850560.0 Cl: 0.14 Test C: 68591235072.0 Cl:0.14658385093167703\n",
      "Epoch 230 Train C: 67607425024.0 Cl: 0.1396551724137931 Test C: 67869323264.0 Cl:0.14658385093167703\n",
      "Epoch 240 Train C: 66893549568.0 Cl: 0.1386206896551724 Test C: 67152162816.0 Cl:0.1468944099378882\n",
      "Epoch 250 Train C: 66185904128.0 Cl: 0.13793103448275862 Test C: 66441183232.0 Cl:0.14658385093167703\n",
      "Epoch 260 Train C: 65482592256.0 Cl: 0.1375862068965517 Test C: 65734623232.0 Cl:0.14503105590062113\n",
      "Epoch 270 Train C: 64784687104.0 Cl: 0.13827586206896553 Test C: 65033723904.0 Cl:0.14440993788819875\n",
      "Epoch 280 Train C: 64091643904.0 Cl: 0.13724137931034483 Test C: 64336605184.0 Cl:0.14440993788819875\n",
      "Epoch 290 Train C: 63403732992.0 Cl: 0.13655172413793104 Test C: 63644082176.0 Cl:0.14440993788819875\n",
      "Epoch 300 Train C: 62721552384.0 Cl: 0.13620689655172413 Test C: 62956515328.0 Cl:0.1437888198757764\n",
      "Epoch 310 Train C: 62042918912.0 Cl: 0.13655172413793104 Test C: 62273003520.0 Cl:0.14347826086956522\n",
      "Epoch 320 Train C: 61369753600.0 Cl: 0.1375862068965517 Test C: 61593645056.0 Cl:0.1437888198757764\n",
      "Epoch 330 Train C: 60702593024.0 Cl: 0.1393103448275862 Test C: 60918837248.0 Cl:0.1437888198757764\n",
      "Epoch 340 Train C: 60041457664.0 Cl: 0.14 Test C: 60248387584.0 Cl:0.1425465838509317\n",
      "Epoch 350 Train C: 59384684544.0 Cl: 0.1396551724137931 Test C: 59583516672.0 Cl:0.14161490683229813\n",
      "Epoch 360 Train C: 58735431680.0 Cl: 0.1396551724137931 Test C: 58924150784.0 Cl:0.14130434782608695\n",
      "Epoch 370 Train C: 58095300608.0 Cl: 0.14103448275862068 Test C: 58272210944.0 Cl:0.1422360248447205\n",
      "Epoch 380 Train C: 57461821440.0 Cl: 0.1413793103448276 Test C: 57625636864.0 Cl:0.14285714285714285\n",
      "Epoch 390 Train C: 56832135168.0 Cl: 0.1406896551724138 Test C: 56982704128.0 Cl:0.14192546583850932\n",
      "Epoch 400 Train C: 56207306752.0 Cl: 0.1406896551724138 Test C: 56345587712.0 Cl:0.14192546583850932\n",
      "Epoch 410 Train C: 55588364288.0 Cl: 0.1403448275862069 Test C: 55714803712.0 Cl:0.14192546583850932\n",
      "Epoch 420 Train C: 54973313024.0 Cl: 0.14 Test C: 55089197056.0 Cl:0.14192546583850932\n",
      "Epoch 430 Train C: 54362320896.0 Cl: 0.14 Test C: 54469505024.0 Cl:0.14192546583850932\n",
      "Epoch 440 Train C: 53756706816.0 Cl: 0.14 Test C: 53856088064.0 Cl:0.14130434782608695\n",
      "Epoch 450 Train C: 53157429248.0 Cl: 0.14 Test C: 53248909312.0 Cl:0.14192546583850932\n",
      "Epoch 460 Train C: 52564185088.0 Cl: 0.1406896551724138 Test C: 52648833024.0 Cl:0.14192546583850932\n",
      "Epoch 470 Train C: 51975057408.0 Cl: 0.1396551724137931 Test C: 52053323776.0 Cl:0.1409937888198758\n",
      "Epoch 480 Train C: 51394236416.0 Cl: 0.1393103448275862 Test C: 51464736768.0 Cl:0.1425465838509317\n",
      "Epoch 490 Train C: 50820628480.0 Cl: 0.13827586206896553 Test C: 50882404352.0 Cl:0.14285714285714285\n",
      "Epoch 500 Train C: 50250846208.0 Cl: 0.13827586206896553 Test C: 50305794048.0 Cl:0.14347826086956522\n",
      "Epoch 510 Train C: 49685909504.0 Cl: 0.1393103448275862 Test C: 49735151616.0 Cl:0.14347826086956522\n",
      "Epoch 520 Train C: 49124724736.0 Cl: 0.14 Test C: 49167745024.0 Cl:0.1437888198757764\n",
      "Epoch 530 Train C: 48568860672.0 Cl: 0.1396551724137931 Test C: 48605356032.0 Cl:0.1437888198757764\n",
      "Epoch 540 Train C: 48017797120.0 Cl: 0.1393103448275862 Test C: 48048476160.0 Cl:0.14440993788819875\n",
      "Epoch 550 Train C: 47472197632.0 Cl: 0.1396551724137931 Test C: 47496429568.0 Cl:0.1453416149068323\n",
      "Epoch 560 Train C: 46932242432.0 Cl: 0.1386206896551724 Test C: 46950445056.0 Cl:0.14472049689440994\n",
      "Epoch 570 Train C: 46398390272.0 Cl: 0.13827586206896553 Test C: 46411165696.0 Cl:0.14440993788819875\n",
      "Epoch 580 Train C: 45869268992.0 Cl: 0.1386206896551724 Test C: 45878624256.0 Cl:0.14440993788819875\n",
      "Epoch 590 Train C: 45347749888.0 Cl: 0.1386206896551724 Test C: 45353271296.0 Cl:0.14409937888198757\n",
      "Epoch 600 Train C: 44832223232.0 Cl: 0.1393103448275862 Test C: 44832813056.0 Cl:0.1453416149068323\n",
      "Epoch 610 Train C: 44323160064.0 Cl: 0.14 Test C: 44317089792.0 Cl:0.14440993788819875\n",
      "Epoch 620 Train C: 43820056576.0 Cl: 0.1406896551724138 Test C: 43805384704.0 Cl:0.14409937888198757\n",
      "Epoch 630 Train C: 43320696832.0 Cl: 0.1396551724137931 Test C: 43298455552.0 Cl:0.14440993788819875\n",
      "Epoch 640 Train C: 42825539584.0 Cl: 0.1386206896551724 Test C: 42797613056.0 Cl:0.14409937888198757\n",
      "Epoch 650 Train C: 42335764480.0 Cl: 0.13827586206896553 Test C: 42301972480.0 Cl:0.1422360248447205\n",
      "Epoch 660 Train C: 41851129856.0 Cl: 0.13724137931034483 Test C: 41811668992.0 Cl:0.14130434782608695\n",
      "Epoch 670 Train C: 41370288128.0 Cl: 0.1375862068965517 Test C: 41325248512.0 Cl:0.1406832298136646\n",
      "Epoch 680 Train C: 40893325312.0 Cl: 0.13793103448275862 Test C: 40843681792.0 Cl:0.14130434782608695\n",
      "Epoch 690 Train C: 40420937728.0 Cl: 0.13793103448275862 Test C: 40365854720.0 Cl:0.1422360248447205\n",
      "Epoch 700 Train C: 39954505728.0 Cl: 0.13724137931034483 Test C: 39892180992.0 Cl:0.1425465838509317\n",
      "Epoch 710 Train C: 39494701056.0 Cl: 0.13896551724137932 Test C: 39425974272.0 Cl:0.14285714285714285\n",
      "Epoch 720 Train C: 39040311296.0 Cl: 0.1403448275862069 Test C: 38964150272.0 Cl:0.1422360248447205\n",
      "Epoch 730 Train C: 38591598592.0 Cl: 0.14103448275862068 Test C: 38508294144.0 Cl:0.1422360248447205\n",
      "Epoch 740 Train C: 38150184960.0 Cl: 0.14103448275862068 Test C: 38062759936.0 Cl:0.14285714285714285\n",
      "Epoch 750 Train C: 37715255296.0 Cl: 0.1406896551724138 Test C: 37623689216.0 Cl:0.1406832298136646\n",
      "Epoch 760 Train C: 37285052416.0 Cl: 0.1406896551724138 Test C: 37192077312.0 Cl:0.14285714285714285\n",
      "Epoch 770 Train C: 36858478592.0 Cl: 0.1406896551724138 Test C: 36765982720.0 Cl:0.14192546583850932\n",
      "Epoch 780 Train C: 36435984384.0 Cl: 0.14310344827586208 Test C: 36343533568.0 Cl:0.14037267080745341\n",
      "Epoch 790 Train C: 36020486144.0 Cl: 0.1424137931034483 Test C: 35926396928.0 Cl:0.1388198757763975\n",
      "Epoch 800 Train C: 35608612864.0 Cl: 0.14310344827586208 Test C: 35513384960.0 Cl:0.14006211180124223\n",
      "Epoch 810 Train C: 35201785856.0 Cl: 0.14275862068965517 Test C: 35106447360.0 Cl:0.13944099378881988\n",
      "Epoch 820 Train C: 34799009792.0 Cl: 0.14344827586206896 Test C: 34703822848.0 Cl:0.1391304347826087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 830 Train C: 34402582528.0 Cl: 0.14275862068965517 Test C: 34307299328.0 Cl:0.1406832298136646\n",
      "Epoch 840 Train C: 34011156480.0 Cl: 0.14310344827586208 Test C: 33915318272.0 Cl:0.1409937888198758\n",
      "Epoch 850 Train C: 33624936448.0 Cl: 0.1413793103448276 Test C: 33527322624.0 Cl:0.1422360248447205\n",
      "Epoch 860 Train C: 33242402816.0 Cl: 0.14 Test C: 33144604672.0 Cl:0.14161490683229813\n",
      "Epoch 870 Train C: 32866635776.0 Cl: 0.1393103448275862 Test C: 32766193664.0 Cl:0.1422360248447205\n",
      "Epoch 880 Train C: 32496871424.0 Cl: 0.1393103448275862 Test C: 32393138176.0 Cl:0.14130434782608695\n",
      "Epoch 890 Train C: 32134946816.0 Cl: 0.1406896551724138 Test C: 32027185152.0 Cl:0.1409937888198758\n",
      "Epoch 900 Train C: 31777777664.0 Cl: 0.14103448275862068 Test C: 31666882560.0 Cl:0.14037267080745341\n",
      "Epoch 910 Train C: 31422840832.0 Cl: 0.1413793103448276 Test C: 31308926976.0 Cl:0.1409937888198758\n",
      "Epoch 920 Train C: 31072225280.0 Cl: 0.14206896551724138 Test C: 30954864640.0 Cl:0.14130434782608695\n",
      "Epoch 930 Train C: 30728118272.0 Cl: 0.14206896551724138 Test C: 30606704640.0 Cl:0.1406832298136646\n",
      "Epoch 940 Train C: 30390532096.0 Cl: 0.1413793103448276 Test C: 30264223744.0 Cl:0.1406832298136646\n",
      "Epoch 950 Train C: 30057713664.0 Cl: 0.14172413793103447 Test C: 29926156288.0 Cl:0.14130434782608695\n",
      "Epoch 960 Train C: 29729247232.0 Cl: 0.14206896551724138 Test C: 29591629824.0 Cl:0.1406832298136646\n",
      "Epoch 970 Train C: 29405372416.0 Cl: 0.1413793103448276 Test C: 29259853824.0 Cl:0.1422360248447205\n",
      "Epoch 980 Train C: 29084993536.0 Cl: 0.14172413793103447 Test C: 28932220928.0 Cl:0.14161490683229813\n",
      "Epoch 990 Train C: 28768147456.0 Cl: 0.1413793103448276 Test C: 28610009088.0 Cl:0.14130434782608695\n",
      "Epoch 1000 Train C: 28456509440.0 Cl: 0.1413793103448276 Test C: 28293273600.0 Cl:0.1409937888198758\n",
      "Epoch 1010 Train C: 28147257344.0 Cl: 0.14103448275862068 Test C: 27979980800.0 Cl:0.14037267080745341\n",
      "Epoch 1020 Train C: 27840387072.0 Cl: 0.1413793103448276 Test C: 27670984704.0 Cl:0.1409937888198758\n",
      "Epoch 1030 Train C: 27537092608.0 Cl: 0.14310344827586208 Test C: 27366017024.0 Cl:0.14037267080745341\n",
      "Epoch 1040 Train C: 27239116800.0 Cl: 0.14413793103448275 Test C: 27065894912.0 Cl:0.14006211180124223\n",
      "Epoch 1050 Train C: 26945308672.0 Cl: 0.14379310344827587 Test C: 26769012736.0 Cl:0.1391304347826087\n",
      "Epoch 1060 Train C: 26654978048.0 Cl: 0.14206896551724138 Test C: 26475220992.0 Cl:0.1388198757763975\n",
      "Epoch 1070 Train C: 26369110016.0 Cl: 0.1403448275862069 Test C: 26184787968.0 Cl:0.13850931677018632\n",
      "Epoch 1080 Train C: 26086942720.0 Cl: 0.14103448275862068 Test C: 25898559488.0 Cl:0.13695652173913042\n",
      "Epoch 1090 Train C: 25809922048.0 Cl: 0.14 Test C: 25617448960.0 Cl:0.13540372670807455\n",
      "Epoch 1100 Train C: 25537748992.0 Cl: 0.1406896551724138 Test C: 25341698048.0 Cl:0.13478260869565217\n",
      "Epoch 1110 Train C: 25267771392.0 Cl: 0.1413793103448276 Test C: 25068161024.0 Cl:0.13540372670807455\n",
      "Epoch 1120 Train C: 25001967616.0 Cl: 0.1424137931034483 Test C: 24797282304.0 Cl:0.1360248447204969\n",
      "Epoch 1130 Train C: 24740278272.0 Cl: 0.14310344827586208 Test C: 24529776640.0 Cl:0.13664596273291926\n",
      "Epoch 1140 Train C: 24481038336.0 Cl: 0.14310344827586208 Test C: 24264720384.0 Cl:0.1372670807453416\n",
      "Epoch 1150 Train C: 24224880640.0 Cl: 0.14206896551724138 Test C: 24002019328.0 Cl:0.1375776397515528\n",
      "Epoch 1160 Train C: 23971274752.0 Cl: 0.14206896551724138 Test C: 23741571072.0 Cl:0.13633540372670808\n",
      "Epoch 1170 Train C: 23720572928.0 Cl: 0.14172413793103447 Test C: 23483058176.0 Cl:0.13664596273291926\n",
      "Epoch 1180 Train C: 23472025600.0 Cl: 0.1406896551724138 Test C: 23226570752.0 Cl:0.13633540372670808\n",
      "Epoch 1190 Train C: 23225364480.0 Cl: 0.1403448275862069 Test C: 22971500544.0 Cl:0.1357142857142857\n",
      "Epoch 1200 Train C: 22980057088.0 Cl: 0.1406896551724138 Test C: 22721032192.0 Cl:0.13478260869565217\n",
      "Epoch 1210 Train C: 22736736256.0 Cl: 0.14103448275862068 Test C: 22475286528.0 Cl:0.1341614906832298\n",
      "Epoch 1220 Train C: 22497609728.0 Cl: 0.13827586206896553 Test C: 22233348096.0 Cl:0.13229813664596274\n",
      "Epoch 1230 Train C: 22263885824.0 Cl: 0.13655172413793104 Test C: 21994891264.0 Cl:0.13229813664596274\n",
      "Epoch 1240 Train C: 22034980864.0 Cl: 0.13620689655172413 Test C: 21761019904.0 Cl:0.13198757763975155\n",
      "Epoch 1250 Train C: 21809444864.0 Cl: 0.13827586206896553 Test C: 21531787264.0 Cl:0.13074534161490683\n",
      "Epoch 1260 Train C: 21586812928.0 Cl: 0.13827586206896553 Test C: 21304442880.0 Cl:0.13043478260869565\n",
      "Epoch 1270 Train C: 21365846016.0 Cl: 0.1375862068965517 Test C: 21080061952.0 Cl:0.12950310559006212\n",
      "Epoch 1280 Train C: 21147146240.0 Cl: 0.13689655172413792 Test C: 20857112576.0 Cl:0.13012422360248446\n",
      "Epoch 1290 Train C: 20931840000.0 Cl: 0.13482758620689655 Test C: 20637558784.0 Cl:0.13105590062111802\n",
      "Epoch 1300 Train C: 20719155200.0 Cl: 0.13586206896551725 Test C: 20420499456.0 Cl:0.13043478260869565\n",
      "Epoch 1310 Train C: 20509706240.0 Cl: 0.13689655172413792 Test C: 20207396864.0 Cl:0.1298136645962733\n",
      "Epoch 1320 Train C: 20302974976.0 Cl: 0.13551724137931034 Test C: 19997110272.0 Cl:0.13105590062111802\n",
      "Epoch 1330 Train C: 20097054720.0 Cl: 0.13448275862068965 Test C: 19787358208.0 Cl:0.13074534161490683\n",
      "Epoch 1340 Train C: 19894026240.0 Cl: 0.13413793103448277 Test C: 19580639232.0 Cl:0.13136645962732918\n",
      "Epoch 1350 Train C: 19692498944.0 Cl: 0.13310344827586207 Test C: 19376220160.0 Cl:0.13167701863354037\n",
      "Epoch 1360 Train C: 19493873664.0 Cl: 0.13241379310344828 Test C: 19175360512.0 Cl:0.13167701863354037\n",
      "Epoch 1370 Train C: 19295954944.0 Cl: 0.13241379310344828 Test C: 18975799296.0 Cl:0.13291925465838508\n",
      "Epoch 1380 Train C: 19099394048.0 Cl: 0.13137931034482758 Test C: 18778642432.0 Cl:0.13167701863354037\n",
      "Epoch 1390 Train C: 18905518080.0 Cl: 0.13241379310344828 Test C: 18583453696.0 Cl:0.13260869565217392\n",
      "Epoch 1400 Train C: 18714744832.0 Cl: 0.13413793103448277 Test C: 18389655552.0 Cl:0.13198757763975155\n",
      "Epoch 1410 Train C: 18525241344.0 Cl: 0.13275862068965516 Test C: 18197569536.0 Cl:0.13136645962732918\n",
      "Epoch 1420 Train C: 18338142208.0 Cl: 0.13379310344827586 Test C: 18007793664.0 Cl:0.13260869565217392\n",
      "Epoch 1430 Train C: 18153410560.0 Cl: 0.13344827586206898 Test C: 17820821504.0 Cl:0.13260869565217392\n",
      "Epoch 1440 Train C: 17969428480.0 Cl: 0.13310344827586207 Test C: 17636245504.0 Cl:0.13198757763975155\n",
      "Epoch 1450 Train C: 17786646528.0 Cl: 0.13241379310344828 Test C: 17453697024.0 Cl:0.13198757763975155\n",
      "Epoch 1460 Train C: 17606238208.0 Cl: 0.1317241379310345 Test C: 17272586240.0 Cl:0.13260869565217392\n",
      "Epoch 1470 Train C: 17427783680.0 Cl: 0.13241379310344828 Test C: 17092435968.0 Cl:0.13136645962732918\n",
      "Epoch 1480 Train C: 17249746944.0 Cl: 0.1317241379310345 Test C: 16913031168.0 Cl:0.13260869565217392\n",
      "Epoch 1490 Train C: 17074954240.0 Cl: 0.13 Test C: 16735953920.0 Cl:0.13354037267080746\n",
      "Epoch 1500 Train C: 16901315584.0 Cl: 0.1289655172413793 Test C: 16561509376.0 Cl:0.13354037267080746\n",
      "Epoch 1510 Train C: 16728616960.0 Cl: 0.1289655172413793 Test C: 16389161984.0 Cl:0.13322981366459627\n",
      "Epoch 1520 Train C: 16557575168.0 Cl: 0.12827586206896552 Test C: 16218725376.0 Cl:0.13540372670807455\n",
      "Epoch 1530 Train C: 16386854912.0 Cl: 0.12724137931034482 Test C: 16048722944.0 Cl:0.13664596273291926\n",
      "Epoch 1540 Train C: 16217451520.0 Cl: 0.12655172413793103 Test C: 15881182208.0 Cl:0.13478260869565217\n",
      "Epoch 1550 Train C: 16049454080.0 Cl: 0.12620689655172415 Test C: 15714577408.0 Cl:0.13478260869565217\n",
      "Epoch 1560 Train C: 15883133952.0 Cl: 0.12620689655172415 Test C: 15548747776.0 Cl:0.13385093167701864\n",
      "Epoch 1570 Train C: 15717478400.0 Cl: 0.12655172413793103 Test C: 15384664064.0 Cl:0.1341614906832298\n",
      "Epoch 1580 Train C: 15553167360.0 Cl: 0.12586206896551724 Test C: 15221822464.0 Cl:0.13322981366459627\n",
      "Epoch 1590 Train C: 15391199232.0 Cl: 0.12724137931034482 Test C: 15061214208.0 Cl:0.13198757763975155\n",
      "Epoch 1600 Train C: 15232399360.0 Cl: 0.12827586206896552 Test C: 14902236160.0 Cl:0.13198757763975155\n",
      "Epoch 1610 Train C: 15075433472.0 Cl: 0.1289655172413793 Test C: 14744065024.0 Cl:0.13291925465838508\n",
      "Epoch 1620 Train C: 14921124864.0 Cl: 0.12931034482758622 Test C: 14587118592.0 Cl:0.13229813664596274\n",
      "Epoch 1630 Train C: 14768352256.0 Cl: 0.1310344827586207 Test C: 14431383552.0 Cl:0.13167701863354037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1640 Train C: 14616550400.0 Cl: 0.1296551724137931 Test C: 14277740544.0 Cl:0.13012422360248446\n",
      "Epoch 1650 Train C: 14464852992.0 Cl: 0.12931034482758622 Test C: 14124375040.0 Cl:0.13198757763975155\n",
      "Epoch 1660 Train C: 14313863168.0 Cl: 0.12931034482758622 Test C: 13973693440.0 Cl:0.13105590062111802\n",
      "Epoch 1670 Train C: 14163525632.0 Cl: 0.13 Test C: 13824269312.0 Cl:0.13136645962732918\n",
      "Epoch 1680 Train C: 14012717056.0 Cl: 0.1296551724137931 Test C: 13675546624.0 Cl:0.13167701863354037\n",
      "Epoch 1690 Train C: 13862122496.0 Cl: 0.1306896551724138 Test C: 13528870912.0 Cl:0.13260869565217392\n",
      "Epoch 1700 Train C: 13712316416.0 Cl: 0.1317241379310345 Test C: 13384169472.0 Cl:0.13509316770186336\n",
      "Epoch 1710 Train C: 13564210176.0 Cl: 0.13241379310344828 Test C: 13240450048.0 Cl:0.134472049689441\n",
      "Epoch 1720 Train C: 13416986624.0 Cl: 0.13310344827586207 Test C: 13098522624.0 Cl:0.13291925465838508\n",
      "Epoch 1730 Train C: 13270497280.0 Cl: 0.13275862068965516 Test C: 12957702144.0 Cl:0.13260869565217392\n",
      "Epoch 1740 Train C: 13124975616.0 Cl: 0.1310344827586207 Test C: 12818089984.0 Cl:0.1341614906832298\n",
      "Epoch 1750 Train C: 12980710400.0 Cl: 0.1306896551724138 Test C: 12680013824.0 Cl:0.134472049689441\n",
      "Epoch 1760 Train C: 12836734976.0 Cl: 0.1317241379310345 Test C: 12542174208.0 Cl:0.13509316770186336\n",
      "Epoch 1770 Train C: 12694263808.0 Cl: 0.1317241379310345 Test C: 12405167104.0 Cl:0.13478260869565217\n",
      "Epoch 1780 Train C: 12552555520.0 Cl: 0.13310344827586207 Test C: 12268469248.0 Cl:0.13509316770186336\n",
      "Epoch 1790 Train C: 12412163072.0 Cl: 0.1317241379310345 Test C: 12134124544.0 Cl:0.1360248447204969\n",
      "Epoch 1800 Train C: 12272859136.0 Cl: 0.13034482758620689 Test C: 12000891904.0 Cl:0.13509316770186336\n",
      "Epoch 1810 Train C: 12134723584.0 Cl: 0.1306896551724138 Test C: 11867848704.0 Cl:0.1360248447204969\n",
      "Epoch 1820 Train C: 11997204480.0 Cl: 0.1310344827586207 Test C: 11735737344.0 Cl:0.1360248447204969\n",
      "Epoch 1830 Train C: 11859991552.0 Cl: 0.13206896551724137 Test C: 11604929536.0 Cl:0.1357142857142857\n",
      "Epoch 1840 Train C: 11723639808.0 Cl: 0.13137931034482758 Test C: 11474940928.0 Cl:0.1341614906832298\n",
      "Epoch 1850 Train C: 11588997120.0 Cl: 0.1306896551724138 Test C: 11345306624.0 Cl:0.13478260869565217\n",
      "Epoch 1860 Train C: 11456024576.0 Cl: 0.13 Test C: 11215739904.0 Cl:0.13385093167701864\n",
      "Epoch 1870 Train C: 11323096064.0 Cl: 0.12931034482758622 Test C: 11087292416.0 Cl:0.13385093167701864\n",
      "Epoch 1880 Train C: 11190780928.0 Cl: 0.13 Test C: 10960000000.0 Cl:0.13509316770186336\n",
      "Epoch 1890 Train C: 11059696640.0 Cl: 0.13137931034482758 Test C: 10834172928.0 Cl:0.1341614906832298\n",
      "Epoch 1900 Train C: 10930129920.0 Cl: 0.13206896551724137 Test C: 10707968000.0 Cl:0.134472049689441\n",
      "Epoch 1910 Train C: 10802055168.0 Cl: 0.1317241379310345 Test C: 10582418432.0 Cl:0.13385093167701864\n",
      "Epoch 1920 Train C: 10674429952.0 Cl: 0.1317241379310345 Test C: 10458391552.0 Cl:0.13229813664596274\n",
      "Epoch 1930 Train C: 10547682304.0 Cl: 0.1306896551724138 Test C: 10335525888.0 Cl:0.13291925465838508\n",
      "Epoch 1940 Train C: 10421863424.0 Cl: 0.13 Test C: 10213566464.0 Cl:0.1341614906832298\n",
      "Epoch 1950 Train C: 10296986624.0 Cl: 0.13 Test C: 10091803648.0 Cl:0.13385093167701864\n",
      "Epoch 1960 Train C: 10173229056.0 Cl: 0.12931034482758622 Test C: 9971441664.0 Cl:0.13322981366459627\n",
      "Epoch 1970 Train C: 10050413568.0 Cl: 0.1289655172413793 Test C: 9851473920.0 Cl:0.13385093167701864\n",
      "Epoch 1980 Train C: 9928137728.0 Cl: 0.13137931034482758 Test C: 9732917248.0 Cl:0.134472049689441\n",
      "Epoch 1990 Train C: 9806658560.0 Cl: 0.1310344827586207 Test C: 9614824448.0 Cl:0.1341614906832298\n",
      "Epoch 2000 Train C: 9685771264.0 Cl: 0.1310344827586207 Test C: 9497229312.0 Cl:0.1341614906832298\n",
      "Epoch 2010 Train C: 9565461504.0 Cl: 0.1310344827586207 Test C: 9380255744.0 Cl:0.1341614906832298\n",
      "Epoch 2020 Train C: 9445950464.0 Cl: 0.13034482758620689 Test C: 9263805440.0 Cl:0.134472049689441\n",
      "Epoch 2030 Train C: 9328111616.0 Cl: 0.1306896551724138 Test C: 9148078080.0 Cl:0.1341614906832298\n",
      "Epoch 2040 Train C: 9211274240.0 Cl: 0.12931034482758622 Test C: 9032564736.0 Cl:0.13633540372670808\n",
      "Epoch 2050 Train C: 9095458816.0 Cl: 0.1289655172413793 Test C: 8918236160.0 Cl:0.1357142857142857\n",
      "Epoch 2060 Train C: 8980364288.0 Cl: 0.12862068965517243 Test C: 8805288960.0 Cl:0.13788819875776398\n",
      "Epoch 2070 Train C: 8866482176.0 Cl: 0.12862068965517243 Test C: 8693257216.0 Cl:0.13695652173913042\n",
      "Epoch 2080 Train C: 8761025536.0 Cl: 0.1296551724137931 Test C: 8588780544.0 Cl:0.1360248447204969\n",
      "Epoch 2090 Train C: 8658367488.0 Cl: 0.13 Test C: 8487432192.0 Cl:0.13633540372670808\n",
      "Epoch 2100 Train C: 8556730880.0 Cl: 0.1289655172413793 Test C: 8387258368.0 Cl:0.1375776397515528\n",
      "Epoch 2110 Train C: 8456281088.0 Cl: 0.12758620689655173 Test C: 8288510464.0 Cl:0.1375776397515528\n",
      "Epoch 2120 Train C: 8356151808.0 Cl: 0.14379310344827587 Test C: 8190660096.0 Cl:0.1546583850931677\n",
      "Epoch 2130 Train C: 8259235328.0 Cl: 0.14517241379310344 Test C: 8096462848.0 Cl:0.15434782608695652\n",
      "Epoch 2140 Train C: 8161846784.0 Cl: 0.1279310344827586 Test C: 8002200576.0 Cl:0.13664596273291926\n",
      "Epoch 2150 Train C: 8064762880.0 Cl: 0.14413793103448275 Test C: 7908364800.0 Cl:0.15559006211180124\n",
      "Epoch 2160 Train C: 7970399232.0 Cl: 0.13 Test C: 7817229312.0 Cl:0.1388198757763975\n",
      "Epoch 2170 Train C: 7874211328.0 Cl: 0.13137931034482758 Test C: 7724591616.0 Cl:0.14037267080745341\n",
      "Epoch 2180 Train C: 7781238272.0 Cl: 0.14517241379310344 Test C: 7634969088.0 Cl:0.1577639751552795\n",
      "Epoch 2190 Train C: 7686435328.0 Cl: 0.13241379310344828 Test C: 7543859712.0 Cl:0.1388198757763975\n",
      "Epoch 2200 Train C: 7594927616.0 Cl: 0.14793103448275863 Test C: 7455816192.0 Cl:0.15869565217391304\n",
      "Epoch 2210 Train C: 7501030400.0 Cl: 0.13379310344827586 Test C: 7365447680.0 Cl:0.1372670807453416\n",
      "Epoch 2220 Train C: 7410191360.0 Cl: 0.13344827586206898 Test C: 7278069760.0 Cl:0.1372670807453416\n",
      "Epoch 2230 Train C: 7318481920.0 Cl: 0.14793103448275863 Test C: 7189668864.0 Cl:0.15869565217391304\n",
      "Epoch 2240 Train C: 7227773440.0 Cl: 0.13551724137931034 Test C: 7101653504.0 Cl:0.13975155279503104\n",
      "Epoch 2250 Train C: 7139100160.0 Cl: 0.13448275862068965 Test C: 7015979520.0 Cl:0.13975155279503104\n",
      "Epoch 2260 Train C: 7049201664.0 Cl: 0.1489655172413793 Test C: 6929216000.0 Cl:0.15869565217391304\n",
      "Epoch 2270 Train C: 6960646144.0 Cl: 0.13620689655172413 Test C: 6842721792.0 Cl:0.13540372670807455\n",
      "Epoch 2280 Train C: 6873629184.0 Cl: 0.13551724137931034 Test C: 6757871616.0 Cl:0.1357142857142857\n",
      "Epoch 2290 Train C: 6786368000.0 Cl: 0.15 Test C: 6672843776.0 Cl:0.15838509316770186\n",
      "Epoch 2300 Train C: 6699112448.0 Cl: 0.15 Test C: 6587300352.0 Cl:0.15900621118012423\n",
      "Epoch 2310 Train C: 6612695552.0 Cl: 0.1496551724137931 Test C: 6501989376.0 Cl:0.15869565217391304\n",
      "Epoch 2320 Train C: 6528602624.0 Cl: 0.13793103448275862 Test C: 6418163200.0 Cl:0.1372670807453416\n",
      "Epoch 2330 Train C: 6445344768.0 Cl: 0.13724137931034483 Test C: 6334753792.0 Cl:0.1357142857142857\n",
      "Epoch 2340 Train C: 6361985536.0 Cl: 0.1496551724137931 Test C: 6251025920.0 Cl:0.15807453416149067\n",
      "Epoch 2350 Train C: 6279071744.0 Cl: 0.1503448275862069 Test C: 6167694848.0 Cl:0.15962732919254657\n",
      "Epoch 2360 Train C: 6196027392.0 Cl: 0.15 Test C: 6084573696.0 Cl:0.15993788819875776\n",
      "Epoch 2370 Train C: 6114514432.0 Cl: 0.1503448275862069 Test C: 6003313664.0 Cl:0.16055900621118013\n",
      "Epoch 2380 Train C: 6033806336.0 Cl: 0.14793103448275863 Test C: 5922022912.0 Cl:0.1608695652173913\n",
      "Epoch 2390 Train C: 5953233920.0 Cl: 0.14724137931034484 Test C: 5840471040.0 Cl:0.16149068322981366\n",
      "Epoch 2400 Train C: 5872966144.0 Cl: 0.13448275862068965 Test C: 5759037440.0 Cl:0.13944099378881988\n",
      "Epoch 2410 Train C: 5793308672.0 Cl: 0.13413793103448277 Test C: 5678652416.0 Cl:0.13819875776397517\n",
      "Epoch 2420 Train C: 5713966592.0 Cl: 0.13413793103448277 Test C: 5598978560.0 Cl:0.1391304347826087\n",
      "Epoch 2430 Train C: 5634756096.0 Cl: 0.13379310344827586 Test C: 5519528448.0 Cl:0.13944099378881988\n",
      "Epoch 2440 Train C: 5555529216.0 Cl: 0.13241379310344828 Test C: 5440357376.0 Cl:0.13850931677018632\n",
      "Epoch 2450 Train C: 5476660736.0 Cl: 0.1482758620689655 Test C: 5361336320.0 Cl:0.16055900621118013\n",
      "Epoch 2460 Train C: 5398337536.0 Cl: 0.14724137931034484 Test C: 5283061760.0 Cl:0.15993788819875776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2470 Train C: 5319372288.0 Cl: 0.14793103448275863 Test C: 5204617216.0 Cl:0.16055900621118013\n",
      "Epoch 2480 Train C: 5240525312.0 Cl: 0.14862068965517242 Test C: 5126397440.0 Cl:0.15962732919254657\n",
      "Epoch 2490 Train C: 5162201600.0 Cl: 0.14862068965517242 Test C: 5049061376.0 Cl:0.15931677018633542\n",
      "Epoch 2500 Train C: 5084778496.0 Cl: 0.15 Test C: 4972450304.0 Cl:0.15931677018633542\n",
      "Epoch 2510 Train C: 5007972352.0 Cl: 0.15 Test C: 4895965696.0 Cl:0.1577639751552795\n",
      "Epoch 2520 Train C: 4931494400.0 Cl: 0.1493103448275862 Test C: 4819928064.0 Cl:0.1565217391304348\n",
      "Epoch 2530 Train C: 4855052800.0 Cl: 0.1493103448275862 Test C: 4743672320.0 Cl:0.15683229813664595\n",
      "Epoch 2540 Train C: 4778899456.0 Cl: 0.1493103448275862 Test C: 4667438592.0 Cl:0.15745341614906833\n",
      "Epoch 2550 Train C: 4703329792.0 Cl: 0.13275862068965516 Test C: 4591834112.0 Cl:0.134472049689441\n",
      "Epoch 2560 Train C: 4627899392.0 Cl: 0.13241379310344828 Test C: 4516576256.0 Cl:0.13260869565217392\n",
      "Epoch 2570 Train C: 4552390656.0 Cl: 0.13241379310344828 Test C: 4441037312.0 Cl:0.1341614906832298\n",
      "Epoch 2580 Train C: 4477647360.0 Cl: 0.13206896551724137 Test C: 4366305792.0 Cl:0.1357142857142857\n",
      "Epoch 2590 Train C: 4402829824.0 Cl: 0.13275862068965516 Test C: 4291641856.0 Cl:0.13478260869565217\n",
      "Epoch 2600 Train C: 4328089088.0 Cl: 0.13448275862068965 Test C: 4217383424.0 Cl:0.134472049689441\n",
      "Epoch 2610 Train C: 4254281472.0 Cl: 0.13379310344827586 Test C: 4144014592.0 Cl:0.13354037267080746\n",
      "Epoch 2620 Train C: 4181454848.0 Cl: 0.13206896551724137 Test C: 4071642624.0 Cl:0.13385093167701864\n",
      "Epoch 2630 Train C: 4109445888.0 Cl: 0.1317241379310345 Test C: 4000106496.0 Cl:0.13509316770186336\n",
      "Epoch 2640 Train C: 4037799424.0 Cl: 0.13241379310344828 Test C: 3928885760.0 Cl:0.13695652173913042\n",
      "Epoch 2650 Train C: 3965980160.0 Cl: 0.13206896551724137 Test C: 3857765120.0 Cl:0.13788819875776398\n",
      "Epoch 2660 Train C: 3894726912.0 Cl: 0.13413793103448277 Test C: 3786962432.0 Cl:0.13788819875776398\n",
      "Epoch 2670 Train C: 3824756992.0 Cl: 0.14758620689655172 Test C: 3716831744.0 Cl:0.1565217391304348\n",
      "Epoch 2680 Train C: 3756275200.0 Cl: 0.1496551724137931 Test C: 3647777792.0 Cl:0.16024844720496895\n",
      "Epoch 2690 Train C: 3687698944.0 Cl: 0.1482758620689655 Test C: 3578938368.0 Cl:0.15931677018633542\n",
      "Epoch 2700 Train C: 3618992896.0 Cl: 0.14655172413793102 Test C: 3510280960.0 Cl:0.15745341614906833\n",
      "Epoch 2710 Train C: 3550103808.0 Cl: 0.13034482758620689 Test C: 3441946368.0 Cl:0.1391304347826087\n",
      "Epoch 2720 Train C: 3481630208.0 Cl: 0.1310344827586207 Test C: 3374268672.0 Cl:0.14006211180124223\n",
      "Epoch 2730 Train C: 3414325504.0 Cl: 0.1317241379310345 Test C: 3307514112.0 Cl:0.14130434782608695\n",
      "Epoch 2740 Train C: 3347807488.0 Cl: 0.13275862068965516 Test C: 3241676544.0 Cl:0.1409937888198758\n",
      "Epoch 2750 Train C: 3282362112.0 Cl: 0.13241379310344828 Test C: 3176669440.0 Cl:0.1409937888198758\n",
      "Epoch 2760 Train C: 3217744640.0 Cl: 0.14413793103448275 Test C: 3112734976.0 Cl:0.15838509316770186\n",
      "Epoch 2770 Train C: 3153921024.0 Cl: 0.14482758620689656 Test C: 3049594368.0 Cl:0.15838509316770186\n",
      "Epoch 2780 Train C: 3090799616.0 Cl: 0.14344827586206896 Test C: 2987059200.0 Cl:0.15838509316770186\n",
      "Epoch 2790 Train C: 3028327168.0 Cl: 0.13310344827586207 Test C: 2925036288.0 Cl:0.14316770186335404\n",
      "Epoch 2800 Train C: 2967093248.0 Cl: 0.13413793103448277 Test C: 2863726848.0 Cl:0.14503105590062113\n",
      "Epoch 2810 Train C: 2906721792.0 Cl: 0.13517241379310344 Test C: 2803442176.0 Cl:0.14409937888198757\n",
      "Epoch 2820 Train C: 2846365696.0 Cl: 0.13482758620689655 Test C: 2743632384.0 Cl:0.14440993788819875\n",
      "Epoch 2830 Train C: 2786903808.0 Cl: 0.13620689655172413 Test C: 2685006336.0 Cl:0.1425465838509317\n",
      "Epoch 2840 Train C: 2727570432.0 Cl: 0.14448275862068966 Test C: 2627018496.0 Cl:0.15962732919254657\n",
      "Epoch 2850 Train C: 2668902912.0 Cl: 0.14655172413793102 Test C: 2569669632.0 Cl:0.16024844720496895\n",
      "Epoch 2860 Train C: 2611363328.0 Cl: 0.14620689655172414 Test C: 2513325056.0 Cl:0.16055900621118013\n",
      "Epoch 2870 Train C: 2555126528.0 Cl: 0.14724137931034484 Test C: 2458322944.0 Cl:0.16211180124223604\n",
      "Epoch 2880 Train C: 2499751680.0 Cl: 0.14206896551724138 Test C: 2403623424.0 Cl:0.14565217391304347\n",
      "Epoch 2890 Train C: 2444622592.0 Cl: 0.14275862068965517 Test C: 2349035264.0 Cl:0.14440993788819875\n",
      "Epoch 2900 Train C: 2390269952.0 Cl: 0.1406896551724138 Test C: 2295625216.0 Cl:0.14347826086956522\n",
      "Epoch 2910 Train C: 2336276224.0 Cl: 0.14103448275862068 Test C: 2243177728.0 Cl:0.1425465838509317\n",
      "Epoch 2920 Train C: 2283473408.0 Cl: 0.1413793103448276 Test C: 2191521792.0 Cl:0.14285714285714285\n",
      "Epoch 2930 Train C: 2232444160.0 Cl: 0.14689655172413793 Test C: 2141238784.0 Cl:0.15838509316770186\n",
      "Epoch 2940 Train C: 2182837248.0 Cl: 0.14655172413793102 Test C: 2092345344.0 Cl:0.15807453416149067\n",
      "Epoch 2950 Train C: 2134036224.0 Cl: 0.14793103448275863 Test C: 2043939968.0 Cl:0.15807453416149067\n",
      "Epoch 2960 Train C: 2085357824.0 Cl: 0.1496551724137931 Test C: 1996167936.0 Cl:0.15993788819875776\n",
      "Epoch 2970 Train C: 2037309952.0 Cl: 0.1489655172413793 Test C: 1949227520.0 Cl:0.15838509316770186\n",
      "Epoch 2980 Train C: 1990985856.0 Cl: 0.1503448275862069 Test C: 1903413376.0 Cl:0.15714285714285714\n",
      "Epoch 2990 Train C: 1945226496.0 Cl: 0.15 Test C: 1858247808.0 Cl:0.15807453416149067\n",
      "Epoch 3000 Train C: 1899884288.0 Cl: 0.15 Test C: 1813593984.0 Cl:0.15714285714285714\n",
      "Epoch 3010 Train C: 1855875072.0 Cl: 0.14172413793103447 Test C: 1770338816.0 Cl:0.1422360248447205\n",
      "Epoch 3020 Train C: 1812144768.0 Cl: 0.1489655172413793 Test C: 1727669632.0 Cl:0.15434782608695652\n",
      "Epoch 3030 Train C: 1769529472.0 Cl: 0.14655172413793102 Test C: 1686131584.0 Cl:0.13944099378881988\n",
      "Epoch 3040 Train C: 1728038272.0 Cl: 0.14689655172413793 Test C: 1645737216.0 Cl:0.15217391304347827\n",
      "Epoch 3050 Train C: 1687086080.0 Cl: 0.14482758620689656 Test C: 1605757696.0 Cl:0.1388198757763975\n",
      "Epoch 3060 Train C: 1647906560.0 Cl: 0.14517241379310344 Test C: 1567058432.0 Cl:0.1409937888198758\n",
      "Epoch 3070 Train C: 1609936640.0 Cl: 0.1493103448275862 Test C: 1529207424.0 Cl:0.15186335403726708\n",
      "Epoch 3080 Train C: 1572209536.0 Cl: 0.1403448275862069 Test C: 1491603456.0 Cl:0.13850931677018632\n",
      "Epoch 3090 Train C: 1535650560.0 Cl: 0.1496551724137931 Test C: 1455761408.0 Cl:0.1496894409937888\n",
      "Epoch 3100 Train C: 1499523584.0 Cl: 0.1503448275862069 Test C: 1420593536.0 Cl:0.1484472049689441\n",
      "Epoch 3110 Train C: 1464231424.0 Cl: 0.14689655172413793 Test C: 1386476416.0 Cl:0.1391304347826087\n",
      "Epoch 3120 Train C: 1429404288.0 Cl: 0.1503448275862069 Test C: 1353150720.0 Cl:0.1496894409937888\n",
      "Epoch 3130 Train C: 1394964736.0 Cl: 0.1503448275862069 Test C: 1320268032.0 Cl:0.15062111801242237\n",
      "Epoch 3140 Train C: 1361461888.0 Cl: 0.14206896551724138 Test C: 1287887488.0 Cl:0.14130434782608695\n",
      "Epoch 3150 Train C: 1329448704.0 Cl: 0.1424137931034483 Test C: 1256358784.0 Cl:0.1409937888198758\n",
      "Epoch 3160 Train C: 1298328704.0 Cl: 0.14551724137931035 Test C: 1225747840.0 Cl:0.13975155279503104\n",
      "Epoch 3170 Train C: 1267574656.0 Cl: 0.14379310344827587 Test C: 1195412480.0 Cl:0.1406832298136646\n",
      "Epoch 3180 Train C: 1237378944.0 Cl: 0.14448275862068966 Test C: 1165516160.0 Cl:0.14006211180124223\n",
      "Epoch 3190 Train C: 1207828480.0 Cl: 0.14379310344827587 Test C: 1136503936.0 Cl:0.1406832298136646\n",
      "Epoch 3200 Train C: 1178659968.0 Cl: 0.14448275862068966 Test C: 1107845504.0 Cl:0.14006211180124223\n",
      "Epoch 3210 Train C: 1150035456.0 Cl: 0.14517241379310344 Test C: 1079779712.0 Cl:0.1409937888198758\n",
      "Epoch 3220 Train C: 1121793024.0 Cl: 0.14586206896551723 Test C: 1052249920.0 Cl:0.14130434782608695\n",
      "Epoch 3230 Train C: 1093857664.0 Cl: 0.14551724137931035 Test C: 1025401024.0 Cl:0.1422360248447205\n",
      "Epoch 3240 Train C: 1066526464.0 Cl: 0.14413793103448275 Test C: 999194752.0 Cl:0.14285714285714285\n",
      "Epoch 3250 Train C: 1039920000.0 Cl: 0.14620689655172414 Test C: 973673664.0 Cl:0.15\n",
      "Epoch 3260 Train C: 1013880448.0 Cl: 0.14758620689655172 Test C: 948531904.0 Cl:0.14347826086956522\n",
      "Epoch 3270 Train C: 988455872.0 Cl: 0.1513793103448276 Test C: 924154368.0 Cl:0.15062111801242237\n",
      "Epoch 3280 Train C: 963852864.0 Cl: 0.15068965517241378 Test C: 900768640.0 Cl:0.1496894409937888\n",
      "Epoch 3290 Train C: 939486336.0 Cl: 0.15172413793103448 Test C: 877795584.0 Cl:0.14937888198757765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3300 Train C: 915442624.0 Cl: 0.14586206896551723 Test C: 855298112.0 Cl:0.1422360248447205\n",
      "Epoch 3310 Train C: 891689344.0 Cl: 0.1493103448275862 Test C: 833520384.0 Cl:0.14906832298136646\n",
      "Epoch 3320 Train C: 868658432.0 Cl: 0.1424137931034483 Test C: 812393728.0 Cl:0.1425465838509317\n",
      "Epoch 3330 Train C: 846065792.0 Cl: 0.14379310344827587 Test C: 792022016.0 Cl:0.14409937888198757\n",
      "Epoch 3340 Train C: 824259392.0 Cl: 0.1496551724137931 Test C: 772570432.0 Cl:0.14906832298136646\n",
      "Epoch 3350 Train C: 802881280.0 Cl: 0.1496551724137931 Test C: 753485760.0 Cl:0.14875776397515528\n",
      "Epoch 3360 Train C: 781855808.0 Cl: 0.15 Test C: 734600768.0 Cl:0.14130434782608695\n",
      "Epoch 3370 Train C: 761239040.0 Cl: 0.1503448275862069 Test C: 716169728.0 Cl:0.1406832298136646\n",
      "Epoch 3380 Train C: 741268416.0 Cl: 0.14655172413793102 Test C: 698265024.0 Cl:0.1425465838509317\n",
      "Epoch 3390 Train C: 722388928.0 Cl: 0.14275862068965517 Test C: 681118272.0 Cl:0.14285714285714285\n",
      "Epoch 3400 Train C: 703728128.0 Cl: 0.1510344827586207 Test C: 664321536.0 Cl:0.14813664596273293\n",
      "Epoch 3410 Train C: 685333504.0 Cl: 0.15379310344827588 Test C: 647896576.0 Cl:0.14596273291925466\n",
      "Epoch 3420 Train C: 667121856.0 Cl: 0.1520689655172414 Test C: 631698240.0 Cl:0.14751552795031056\n",
      "Epoch 3430 Train C: 649832448.0 Cl: 0.15068965517241378 Test C: 615934208.0 Cl:0.14751552795031056\n",
      "Epoch 3440 Train C: 633387200.0 Cl: 0.15172413793103448 Test C: 600629376.0 Cl:0.14937888198757765\n",
      "Epoch 3450 Train C: 617217792.0 Cl: 0.15551724137931033 Test C: 585630976.0 Cl:0.14813664596273293\n",
      "Epoch 3460 Train C: 601056384.0 Cl: 0.15448275862068966 Test C: 570657024.0 Cl:0.14720496894409937\n",
      "Epoch 3470 Train C: 585485376.0 Cl: 0.1520689655172414 Test C: 556282432.0 Cl:0.1484472049689441\n",
      "Epoch 3480 Train C: 570258048.0 Cl: 0.1489655172413793 Test C: 542079232.0 Cl:0.14565217391304347\n",
      "Epoch 3490 Train C: 555607808.0 Cl: 0.14862068965517242 Test C: 528221536.0 Cl:0.1453416149068323\n",
      "Epoch 3500 Train C: 541380672.0 Cl: 0.15275862068965518 Test C: 514790720.0 Cl:0.1484472049689441\n",
      "Epoch 3510 Train C: 527313504.0 Cl: 0.15448275862068966 Test C: 501668960.0 Cl:0.1468944099378882\n",
      "Epoch 3520 Train C: 513669216.0 Cl: 0.1520689655172414 Test C: 488575712.0 Cl:0.14720496894409937\n",
      "Epoch 3530 Train C: 500578336.0 Cl: 0.1520689655172414 Test C: 476070848.0 Cl:0.14782608695652175\n",
      "Epoch 3540 Train C: 487929792.0 Cl: 0.14551724137931035 Test C: 464298464.0 Cl:0.1425465838509317\n",
      "Epoch 3550 Train C: 475441536.0 Cl: 0.1520689655172414 Test C: 452817600.0 Cl:0.14782608695652175\n",
      "Epoch 3560 Train C: 463478624.0 Cl: 0.14724137931034484 Test C: 441748896.0 Cl:0.14503105590062113\n",
      "Epoch 3570 Train C: 451628960.0 Cl: 0.1520689655172414 Test C: 431021856.0 Cl:0.14813664596273293\n",
      "Epoch 3580 Train C: 440041696.0 Cl: 0.1489655172413793 Test C: 420612736.0 Cl:0.1468944099378882\n",
      "Epoch 3590 Train C: 428715904.0 Cl: 0.15241379310344827 Test C: 410494912.0 Cl:0.14782608695652175\n",
      "Epoch 3600 Train C: 417881536.0 Cl: 0.1513793103448276 Test C: 400507904.0 Cl:0.14782608695652175\n",
      "Epoch 3610 Train C: 407705696.0 Cl: 0.15413793103448276 Test C: 390727776.0 Cl:0.14751552795031056\n",
      "Epoch 3620 Train C: 397907968.0 Cl: 0.15379310344827588 Test C: 381357888.0 Cl:0.14720496894409937\n",
      "Epoch 3630 Train C: 388332256.0 Cl: 0.1513793103448276 Test C: 372286720.0 Cl:0.14813664596273293\n",
      "Epoch 3640 Train C: 378710880.0 Cl: 0.15379310344827588 Test C: 363202912.0 Cl:0.14627329192546584\n",
      "Epoch 3650 Train C: 369321056.0 Cl: 0.1510344827586207 Test C: 354237888.0 Cl:0.14720496894409937\n",
      "Epoch 3660 Train C: 360071840.0 Cl: 0.1520689655172414 Test C: 345700480.0 Cl:0.14813664596273293\n",
      "Epoch 3670 Train C: 351314336.0 Cl: 0.1520689655172414 Test C: 337769664.0 Cl:0.1484472049689441\n",
      "Epoch 3680 Train C: 342625472.0 Cl: 0.1510344827586207 Test C: 330052576.0 Cl:0.14906832298136646\n",
      "Epoch 3690 Train C: 333892288.0 Cl: 0.15413793103448276 Test C: 322456160.0 Cl:0.14751552795031056\n",
      "Epoch 3700 Train C: 325516320.0 Cl: 0.1513793103448276 Test C: 315173056.0 Cl:0.14813664596273293\n",
      "Epoch 3710 Train C: 317130496.0 Cl: 0.15310344827586206 Test C: 307913760.0 Cl:0.14813664596273293\n",
      "Epoch 3720 Train C: 309156352.0 Cl: 0.15344827586206897 Test C: 300791520.0 Cl:0.14751552795031056\n",
      "Epoch 3730 Train C: 301429856.0 Cl: 0.15172413793103448 Test C: 293808160.0 Cl:0.14782608695652175\n",
      "Epoch 3740 Train C: 293825952.0 Cl: 0.1510344827586207 Test C: 286821024.0 Cl:0.14751552795031056\n",
      "Epoch 3750 Train C: 286301152.0 Cl: 0.14793103448275863 Test C: 280008608.0 Cl:0.14658385093167703\n",
      "Epoch 3760 Train C: 279024256.0 Cl: 0.1503448275862069 Test C: 273514240.0 Cl:0.14875776397515528\n",
      "Epoch 3770 Train C: 271974560.0 Cl: 0.1493103448275862 Test C: 267229120.0 Cl:0.14937888198757765\n",
      "Epoch 3780 Train C: 265299488.0 Cl: 0.15172413793103448 Test C: 261123008.0 Cl:0.1484472049689441\n",
      "Epoch 3790 Train C: 258576464.0 Cl: 0.1489655172413793 Test C: 255055472.0 Cl:0.1496894409937888\n",
      "Epoch 3800 Train C: 252100592.0 Cl: 0.1489655172413793 Test C: 249164832.0 Cl:0.15062111801242237\n",
      "Epoch 3810 Train C: 245695600.0 Cl: 0.1510344827586207 Test C: 243505488.0 Cl:0.1484472049689441\n",
      "Epoch 3820 Train C: 239389968.0 Cl: 0.1493103448275862 Test C: 237998112.0 Cl:0.15062111801242237\n",
      "Epoch 3830 Train C: 233124576.0 Cl: 0.15068965517241378 Test C: 232531392.0 Cl:0.15031055900621118\n",
      "Epoch 3840 Train C: 226818384.0 Cl: 0.14724137931034484 Test C: 227084768.0 Cl:0.14782608695652175\n",
      "Epoch 3850 Train C: 220880608.0 Cl: 0.15 Test C: 221732224.0 Cl:0.15031055900621118\n",
      "Epoch 3860 Train C: 215235184.0 Cl: 0.15241379310344827 Test C: 216533728.0 Cl:0.14906832298136646\n",
      "Epoch 3870 Train C: 209837952.0 Cl: 0.15 Test C: 211498912.0 Cl:0.14751552795031056\n",
      "Epoch 3880 Train C: 204758448.0 Cl: 0.15275862068965518 Test C: 206776464.0 Cl:0.1496894409937888\n",
      "Epoch 3890 Train C: 199867824.0 Cl: 0.15275862068965518 Test C: 202280176.0 Cl:0.14937888198757765\n",
      "Epoch 3900 Train C: 195067744.0 Cl: 0.15310344827586206 Test C: 197904976.0 Cl:0.1496894409937888\n",
      "Epoch 3910 Train C: 190391440.0 Cl: 0.15310344827586206 Test C: 193648384.0 Cl:0.1496894409937888\n",
      "Epoch 3920 Train C: 185665360.0 Cl: 0.15 Test C: 189341488.0 Cl:0.1496894409937888\n",
      "Epoch 3930 Train C: 181053648.0 Cl: 0.1496551724137931 Test C: 185191648.0 Cl:0.15\n",
      "Epoch 3940 Train C: 176419056.0 Cl: 0.15379310344827588 Test C: 181049392.0 Cl:0.1484472049689441\n",
      "Epoch 3950 Train C: 171828320.0 Cl: 0.15275862068965518 Test C: 176897248.0 Cl:0.14906832298136646\n",
      "Epoch 3960 Train C: 167331712.0 Cl: 0.1503448275862069 Test C: 172657440.0 Cl:0.15\n",
      "Epoch 3970 Train C: 163029440.0 Cl: 0.1513793103448276 Test C: 168491520.0 Cl:0.14937888198757765\n",
      "Epoch 3980 Train C: 158979248.0 Cl: 0.15448275862068966 Test C: 164441296.0 Cl:0.14782608695652175\n",
      "Epoch 3990 Train C: 155124864.0 Cl: 0.15310344827586206 Test C: 160420896.0 Cl:0.1484472049689441\n",
      "Epoch 4000 Train C: 151550960.0 Cl: 0.15379310344827588 Test C: 156562416.0 Cl:0.14875776397515528\n",
      "Epoch 4010 Train C: 148146032.0 Cl: 0.15068965517241378 Test C: 152797136.0 Cl:0.14875776397515528\n",
      "Epoch 4020 Train C: 144673392.0 Cl: 0.15310344827586206 Test C: 149078528.0 Cl:0.1468944099378882\n",
      "Epoch 4030 Train C: 141323840.0 Cl: 0.15310344827586206 Test C: 145494240.0 Cl:0.14813664596273293\n",
      "Epoch 4040 Train C: 138163792.0 Cl: 0.15310344827586206 Test C: 142082848.0 Cl:0.1484472049689441\n",
      "Epoch 4050 Train C: 135096288.0 Cl: 0.15379310344827588 Test C: 138727744.0 Cl:0.14937888198757765\n",
      "Epoch 4060 Train C: 132057400.0 Cl: 0.1510344827586207 Test C: 135421488.0 Cl:0.1512422360248447\n",
      "Epoch 4070 Train C: 128987048.0 Cl: 0.15310344827586206 Test C: 132205080.0 Cl:0.14906832298136646\n",
      "Epoch 4080 Train C: 126006248.0 Cl: 0.15344827586206897 Test C: 129064560.0 Cl:0.14906832298136646\n",
      "Epoch 4090 Train C: 123032640.0 Cl: 0.15310344827586206 Test C: 125976888.0 Cl:0.1484472049689441\n",
      "Epoch 4100 Train C: 120122960.0 Cl: 0.15310344827586206 Test C: 122950800.0 Cl:0.14875776397515528\n",
      "Epoch 4110 Train C: 117282456.0 Cl: 0.1510344827586207 Test C: 119956280.0 Cl:0.15217391304347827\n",
      "Epoch 4120 Train C: 114452520.0 Cl: 0.1520689655172414 Test C: 117050928.0 Cl:0.14906832298136646\n",
      "Epoch 4130 Train C: 111724632.0 Cl: 0.15241379310344827 Test C: 114264480.0 Cl:0.15279503105590062\n",
      "Epoch 4140 Train C: 109079224.0 Cl: 0.1513793103448276 Test C: 111647600.0 Cl:0.1515527950310559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4150 Train C: 106420248.0 Cl: 0.1510344827586207 Test C: 109139968.0 Cl:0.1512422360248447\n",
      "Epoch 4160 Train C: 103813160.0 Cl: 0.1520689655172414 Test C: 106702136.0 Cl:0.15248447204968943\n",
      "Epoch 4170 Train C: 101253976.0 Cl: 0.15172413793103448 Test C: 104379184.0 Cl:0.15279503105590062\n",
      "Epoch 4180 Train C: 98780176.0 Cl: 0.15241379310344827 Test C: 102143704.0 Cl:0.153416149068323\n",
      "Epoch 4190 Train C: 96435480.0 Cl: 0.1520689655172414 Test C: 99997248.0 Cl:0.1531055900621118\n",
      "Epoch 4200 Train C: 94185392.0 Cl: 0.1510344827586207 Test C: 97889864.0 Cl:0.1515527950310559\n",
      "Epoch 4210 Train C: 92085560.0 Cl: 0.1520689655172414 Test C: 95837544.0 Cl:0.14906832298136646\n",
      "Epoch 4220 Train C: 90038360.0 Cl: 0.15068965517241378 Test C: 93780712.0 Cl:0.1515527950310559\n",
      "Epoch 4230 Train C: 88268808.0 Cl: 0.1503448275862069 Test C: 91832256.0 Cl:0.1512422360248447\n",
      "Epoch 4240 Train C: 86524512.0 Cl: 0.1482758620689655 Test C: 89891016.0 Cl:0.1515527950310559\n",
      "Epoch 4250 Train C: 84773816.0 Cl: 0.1482758620689655 Test C: 87909880.0 Cl:0.1515527950310559\n",
      "Epoch 4260 Train C: 83009016.0 Cl: 0.1482758620689655 Test C: 85954440.0 Cl:0.1512422360248447\n",
      "Epoch 4270 Train C: 81269328.0 Cl: 0.15 Test C: 84025648.0 Cl:0.14906832298136646\n",
      "Epoch 4280 Train C: 79549096.0 Cl: 0.14793103448275863 Test C: 82146976.0 Cl:0.1512422360248447\n",
      "Epoch 4290 Train C: 77919928.0 Cl: 0.14689655172413793 Test C: 80257096.0 Cl:0.15031055900621118\n",
      "Epoch 4300 Train C: 76335664.0 Cl: 0.15 Test C: 78404872.0 Cl:0.15093167701863355\n",
      "Epoch 4310 Train C: 74780760.0 Cl: 0.14724137931034484 Test C: 76581608.0 Cl:0.1484472049689441\n",
      "Epoch 4320 Train C: 73266376.0 Cl: 0.14758620689655172 Test C: 74738264.0 Cl:0.1512422360248447\n",
      "Epoch 4330 Train C: 71792032.0 Cl: 0.14758620689655172 Test C: 72926608.0 Cl:0.1512422360248447\n",
      "Epoch 4340 Train C: 70325096.0 Cl: 0.15 Test C: 71141728.0 Cl:0.15062111801242237\n",
      "Epoch 4350 Train C: 68951632.0 Cl: 0.15 Test C: 69465656.0 Cl:0.1484472049689441\n",
      "Epoch 4360 Train C: 67585528.0 Cl: 0.1496551724137931 Test C: 67808160.0 Cl:0.1496894409937888\n",
      "Epoch 4370 Train C: 66249112.0 Cl: 0.14862068965517242 Test C: 66262660.0 Cl:0.1512422360248447\n",
      "Epoch 4380 Train C: 64939836.0 Cl: 0.1496551724137931 Test C: 64806820.0 Cl:0.1515527950310559\n",
      "Epoch 4390 Train C: 63669884.0 Cl: 0.1503448275862069 Test C: 63349952.0 Cl:0.14813664596273293\n",
      "Epoch 4400 Train C: 62432832.0 Cl: 0.1493103448275862 Test C: 61902552.0 Cl:0.1515527950310559\n",
      "Epoch 4410 Train C: 61213776.0 Cl: 0.1496551724137931 Test C: 60479944.0 Cl:0.1515527950310559\n",
      "Epoch 4420 Train C: 60000840.0 Cl: 0.14862068965517242 Test C: 59068484.0 Cl:0.15\n",
      "Epoch 4430 Train C: 58789096.0 Cl: 0.1493103448275862 Test C: 57684340.0 Cl:0.1512422360248447\n",
      "Epoch 4440 Train C: 57567912.0 Cl: 0.1513793103448276 Test C: 56337020.0 Cl:0.14906832298136646\n",
      "Epoch 4450 Train C: 56433320.0 Cl: 0.1493103448275862 Test C: 54979524.0 Cl:0.1515527950310559\n",
      "Epoch 4460 Train C: 55389112.0 Cl: 0.15 Test C: 53689588.0 Cl:0.15186335403726708\n",
      "Epoch 4470 Train C: 54355056.0 Cl: 0.1493103448275862 Test C: 52488076.0 Cl:0.14906832298136646\n",
      "Epoch 4480 Train C: 53323084.0 Cl: 0.1496551724137931 Test C: 51351352.0 Cl:0.1512422360248447\n",
      "Epoch 4490 Train C: 52279128.0 Cl: 0.1520689655172414 Test C: 50228016.0 Cl:0.15\n",
      "Epoch 4500 Train C: 51245564.0 Cl: 0.1520689655172414 Test C: 49150204.0 Cl:0.14937888198757765\n",
      "Epoch 4510 Train C: 50266892.0 Cl: 0.15 Test C: 48052488.0 Cl:0.15031055900621118\n",
      "Epoch 4520 Train C: 49315808.0 Cl: 0.15172413793103448 Test C: 46944244.0 Cl:0.15031055900621118\n",
      "Epoch 4530 Train C: 48424080.0 Cl: 0.1513793103448276 Test C: 45829832.0 Cl:0.1484472049689441\n",
      "Epoch 4540 Train C: 47540300.0 Cl: 0.15 Test C: 44753996.0 Cl:0.1496894409937888\n",
      "Epoch 4550 Train C: 46685092.0 Cl: 0.15068965517241378 Test C: 43691448.0 Cl:0.1512422360248447\n",
      "Epoch 4560 Train C: 45827024.0 Cl: 0.1503448275862069 Test C: 42659624.0 Cl:0.1512422360248447\n",
      "Epoch 4570 Train C: 44969100.0 Cl: 0.15172413793103448 Test C: 41708508.0 Cl:0.1496894409937888\n",
      "Epoch 4580 Train C: 44126376.0 Cl: 0.1513793103448276 Test C: 40849420.0 Cl:0.14906832298136646\n",
      "Epoch 4590 Train C: 43291636.0 Cl: 0.1496551724137931 Test C: 39996192.0 Cl:0.14906832298136646\n",
      "Epoch 4600 Train C: 42473844.0 Cl: 0.1496551724137931 Test C: 39149696.0 Cl:0.15031055900621118\n",
      "Epoch 4610 Train C: 41671032.0 Cl: 0.1496551724137931 Test C: 38375224.0 Cl:0.14875776397515528\n",
      "Epoch 4620 Train C: 40859356.0 Cl: 0.1513793103448276 Test C: 37645564.0 Cl:0.1496894409937888\n",
      "Epoch 4630 Train C: 40051916.0 Cl: 0.1493103448275862 Test C: 36934168.0 Cl:0.14906832298136646\n",
      "Epoch 4640 Train C: 39242232.0 Cl: 0.1496551724137931 Test C: 36224264.0 Cl:0.15093167701863355\n",
      "Epoch 4650 Train C: 38427820.0 Cl: 0.1496551724137931 Test C: 35515724.0 Cl:0.14906832298136646\n",
      "Epoch 4660 Train C: 37624372.0 Cl: 0.1496551724137931 Test C: 34816564.0 Cl:0.1515527950310559\n",
      "Epoch 4670 Train C: 36831716.0 Cl: 0.15 Test C: 34125964.0 Cl:0.1512422360248447\n",
      "Epoch 4680 Train C: 36074400.0 Cl: 0.1493103448275862 Test C: 33489888.0 Cl:0.15062111801242237\n",
      "Epoch 4690 Train C: 35330484.0 Cl: 0.15172413793103448 Test C: 32874208.0 Cl:0.15\n",
      "Epoch 4700 Train C: 34628936.0 Cl: 0.15 Test C: 32278606.0 Cl:0.15093167701863355\n",
      "Epoch 4710 Train C: 33924008.0 Cl: 0.15172413793103448 Test C: 31684636.0 Cl:0.15\n",
      "Epoch 4720 Train C: 33243452.0 Cl: 0.15 Test C: 31113238.0 Cl:0.15093167701863355\n",
      "Epoch 4730 Train C: 32576418.0 Cl: 0.1489655172413793 Test C: 30571552.0 Cl:0.15\n",
      "Epoch 4740 Train C: 31900232.0 Cl: 0.1510344827586207 Test C: 30015264.0 Cl:0.15093167701863355\n",
      "Epoch 4750 Train C: 31283692.0 Cl: 0.15 Test C: 29450486.0 Cl:0.1512422360248447\n",
      "Epoch 4760 Train C: 30647514.0 Cl: 0.14862068965517242 Test C: 28853718.0 Cl:0.15062111801242237\n",
      "Epoch 4770 Train C: 29909032.0 Cl: 0.1496551724137931 Test C: 28190010.0 Cl:0.15\n",
      "Epoch 4780 Train C: 29205562.0 Cl: 0.1496551724137931 Test C: 27552448.0 Cl:0.1512422360248447\n",
      "Epoch 4790 Train C: 28462050.0 Cl: 0.1493103448275862 Test C: 26926590.0 Cl:0.14937888198757765\n",
      "Epoch 4800 Train C: 27738172.0 Cl: 0.1503448275862069 Test C: 26355280.0 Cl:0.1512422360248447\n",
      "Epoch 4810 Train C: 27030598.0 Cl: 0.15 Test C: 25789260.0 Cl:0.15\n",
      "Epoch 4820 Train C: 26329684.0 Cl: 0.1496551724137931 Test C: 25221432.0 Cl:0.15031055900621118\n",
      "Epoch 4830 Train C: 25712224.0 Cl: 0.1493103448275862 Test C: 24682972.0 Cl:0.15093167701863355\n",
      "Epoch 4840 Train C: 25116516.0 Cl: 0.1493103448275862 Test C: 24149346.0 Cl:0.15031055900621118\n",
      "Epoch 4850 Train C: 24513128.0 Cl: 0.1496551724137931 Test C: 23633086.0 Cl:0.15093167701863355\n",
      "Epoch 4860 Train C: 23912998.0 Cl: 0.1493103448275862 Test C: 23143578.0 Cl:0.15031055900621118\n",
      "Epoch 4870 Train C: 23307824.0 Cl: 0.15 Test C: 22645520.0 Cl:0.15062111801242237\n",
      "Epoch 4880 Train C: 22684774.0 Cl: 0.1489655172413793 Test C: 22140800.0 Cl:0.15031055900621118\n",
      "Epoch 4890 Train C: 22123220.0 Cl: 0.1496551724137931 Test C: 21642394.0 Cl:0.15\n",
      "Epoch 4900 Train C: 21571876.0 Cl: 0.15 Test C: 21168224.0 Cl:0.1496894409937888\n",
      "Epoch 4910 Train C: 21071792.0 Cl: 0.1496551724137931 Test C: 20716846.0 Cl:0.15093167701863355\n",
      "Epoch 4920 Train C: 20655948.0 Cl: 0.1493103448275862 Test C: 20355776.0 Cl:0.14937888198757765\n"
     ]
    }
   ],
   "source": [
    "a.fit(X_train,y_train,lr=0.0001,epochs=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 3., 3., ..., 1., 0., 6.], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
